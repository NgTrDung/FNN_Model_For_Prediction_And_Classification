{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from sklearn.metrics  import accuracy_score,f1_score,precision_score,recall_score\n",
    "from keras.activations import relu\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np \n",
    "import regex as re \n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Proprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Read the file and divide it into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_sentence_list(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    sentences = [sentence.strip() for sentence in re.split(r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
    "    return sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Create a dictionary for each word in the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ho Chi Minh City University of Technology and Education, with a long and prestigious history in the field of education and research, is a modern school with a rich and diverse learning and research environment.', 'Located in the city center, Ho Chi Minh City University of Technology and Education is not only a provider of professional knowledge but also a vibrant and creative academic community.', 'With modern facilities, classrooms, laboratories and libraries are fully equipped, creating favorable conditions for students and lecturers in the learning and research process.', 'The school is also proud of its team of experienced, highly qualified lecturers who are committed to providing students with the best support and development.', 'Training programs are diverse, flexible and reflect the actual needs of the labor market, giving students the opportunity to develop themselves and prepare for their future careers.', 'In addition, the school also promotes international research and cooperation, creating conditions for students to participate in research projects and exchange with students and lecturers from universities around the world.', '.', 'In short, the University of Technical Education is an ideal learning and research environment, where creativity and discovery are awakened and developed.']\n",
      "{'and': 1, 'the': 2, 'of': 3, 'in': 4, 'research': 5, 'with': 6, 'a': 7, 'students': 8, 'education': 9, 'is': 10, 'are': 11, 'city': 12, 'university': 13, 'school': 14, 'learning': 15, 'also': 16, 'for': 17, 'lecturers': 18, 'to': 19, 'ho': 20, 'chi': 21, 'minh': 22, 'technology': 23, 'modern': 24, 'diverse': 25, 'environment': 26, 'creating': 27, 'conditions': 28, 'long': 29, 'prestigious': 30, 'history': 31, 'field': 32, 'rich': 33, 'located': 34, 'center': 35, 'not': 36, 'only': 37, 'provider': 38, 'professional': 39, 'knowledge': 40, 'but': 41, 'vibrant': 42, 'creative': 43, 'academic': 44, 'community': 45, 'facilities': 46, 'classrooms': 47, 'laboratories': 48, 'libraries': 49, 'fully': 50, 'equipped': 51, 'favorable': 52, 'process': 53, 'proud': 54, 'its': 55, 'team': 56, 'experienced': 57, 'highly': 58, 'qualified': 59, 'who': 60, 'committed': 61, 'providing': 62, 'best': 63, 'support': 64, 'development': 65, 'training': 66, 'programs': 67, 'flexible': 68, 'reflect': 69, 'actual': 70, 'needs': 71, 'labor': 72, 'market': 73, 'giving': 74, 'opportunity': 75, 'develop': 76, 'themselves': 77, 'prepare': 78, 'their': 79, 'future': 80, 'careers': 81, 'addition': 82, 'promotes': 83, 'international': 84, 'cooperation': 85, 'participate': 86, 'projects': 87, 'exchange': 88, 'from': 89, 'universities': 90, 'around': 91, 'world': 92, 'short': 93, 'technical': 94, 'an': 95, 'ideal': 96, 'where': 97, 'creativity': 98, 'discovery': 99, 'awakened': 100, 'developed': 101}\n"
     ]
    }
   ],
   "source": [
    "file_path = 'train.txt'\n",
    "text_data = file_to_sentence_list(file_path)\n",
    "print(text_data)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data) \n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Create Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 21], [20, 21, 22], [20, 21, 22, 12], [20, 21, 22, 12, 13], [20, 21, 22, 12, 13, 3], [20, 21, 22, 12, 13, 3, 23], [20, 21, 22, 12, 13, 3, 23, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15, 1, 5], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15, 1, 5, 26], [34, 4], [34, 4, 2], [34, 4, 2, 12], [34, 4, 2, 12, 35], [34, 4, 2, 12, 35, 20], [34, 4, 2, 12, 35, 20, 21], [34, 4, 2, 12, 35, 20, 21, 22], [34, 4, 2, 12, 35, 20, 21, 22, 12], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1, 43], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1, 43, 44], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1, 43, 44, 45], [6, 24], [6, 24, 46], [6, 24, 46, 47], [6, 24, 46, 47, 48], [6, 24, 46, 47, 48, 1], [6, 24, 46, 47, 48, 1, 49], [6, 24, 46, 47, 48, 1, 49, 11], [6, 24, 46, 47, 48, 1, 49, 11, 50], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15, 1], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15, 1, 5], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15, 1, 5, 53], [2, 14], [2, 14, 10], [2, 14, 10, 16], [2, 14, 10, 16, 54], [2, 14, 10, 16, 54, 3], [2, 14, 10, 16, 54, 3, 55], [2, 14, 10, 16, 54, 3, 55, 56], [2, 14, 10, 16, 54, 3, 55, 56, 3], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63, 64], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63, 64, 1], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63, 64, 1, 65], [66, 67], [66, 67, 11], [66, 67, 11, 25], [66, 67, 11, 25, 68], [66, 67, 11, 25, 68, 1], [66, 67, 11, 25, 68, 1, 69], [66, 67, 11, 25, 68, 1, 69, 2], [66, 67, 11, 25, 68, 1, 69, 2, 70], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17, 79], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17, 79, 80], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17, 79, 80, 81], [4, 82], [4, 82, 2], [4, 82, 2, 14], [4, 82, 2, 14, 16], [4, 82, 2, 14, 16, 83], [4, 82, 2, 14, 16, 83, 84], [4, 82, 2, 14, 16, 83, 84, 5], [4, 82, 2, 14, 16, 83, 84, 5, 1], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90, 91], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90, 91, 2], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90, 91, 2, 92], [4, 93], [4, 93, 2], [4, 93, 2, 13], [4, 93, 2, 13, 3], [4, 93, 2, 13, 3, 94], [4, 93, 2, 13, 3, 94, 9], [4, 93, 2, 13, 3, 94, 9, 10], [4, 93, 2, 13, 3, 94, 9, 10, 95], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11, 100], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11, 100, 1], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11, 100, 1, 101]]\n"
     ]
    }
   ],
   "source": [
    "def CreateInput(text_data):\n",
    "    input_sequences = []\n",
    "    for line in text_data:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences\n",
    "input_sequences=CreateInput(text_data)\n",
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.Convert to full vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Divide the data set into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y =to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Configuration RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, name='embedding_layer')) \n",
    "model.add(SimpleRNN(8, return_sequences=True, activation=relu, name='rnn_layer_1'))\n",
    "model.add(SimpleRNN(9, return_sequences=True, activation=relu, name='rnn_layer_2'))\n",
    "model.add(SimpleRNN(9, activation=relu, name='rnn_layer_3'))\n",
    "model.add(Dense(total_words, activation='softmax', name='output_layer'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Trainning RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.0090 - loss: 4.6247    \n",
      "Epoch 2/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0581 - loss: 4.6212\n",
      "Epoch 3/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1037 - loss: 4.6178 \n",
      "Epoch 4/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1141 - loss: 4.6136\n",
      "Epoch 5/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0913 - loss: 4.6100\n",
      "Epoch 6/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1055 - loss: 4.6038 \n",
      "Epoch 7/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0616 - loss: 4.6007   \n",
      "Epoch 8/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1044 - loss: 4.5905\n",
      "Epoch 9/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0987 - loss: 4.5805\n",
      "Epoch 10/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0963 - loss: 4.5719\n",
      "Epoch 11/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0897 - loss: 4.5481\n",
      "Epoch 12/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1096 - loss: 4.5249\n",
      "Epoch 13/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0821 - loss: 4.4866\n",
      "Epoch 14/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0873 - loss: 4.4470\n",
      "Epoch 15/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1026 - loss: 4.3793\n",
      "Epoch 16/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0998 - loss: 4.3560\n",
      "Epoch 17/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1383 - loss: 4.1810\n",
      "Epoch 18/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1205 - loss: 4.2340\n",
      "Epoch 19/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1044 - loss: 4.1285\n",
      "Epoch 20/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1024 - loss: 4.1258\n",
      "Epoch 21/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1062 - loss: 4.1031\n",
      "Epoch 22/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0978 - loss: 4.0539\n",
      "Epoch 23/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1225 - loss: 3.9415\n",
      "Epoch 24/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1294 - loss: 3.8871\n",
      "Epoch 25/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1293 - loss: 3.8929\n",
      "Epoch 26/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0875 - loss: 3.8517\n",
      "Epoch 27/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0675 - loss: 3.9383\n",
      "Epoch 28/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0969 - loss: 3.8760 \n",
      "Epoch 29/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1342 - loss: 3.8069\n",
      "Epoch 30/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1096 - loss: 3.7958\n",
      "Epoch 31/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1289 - loss: 3.8271 \n",
      "Epoch 32/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1541 - loss: 3.6342\n",
      "Epoch 33/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1322 - loss: 3.7213\n",
      "Epoch 34/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1505 - loss: 3.6738\n",
      "Epoch 35/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1815 - loss: 3.6186\n",
      "Epoch 36/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1495 - loss: 3.5909\n",
      "Epoch 37/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1830 - loss: 3.5335\n",
      "Epoch 38/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1372 - loss: 3.5653   \n",
      "Epoch 39/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1865 - loss: 3.5579\n",
      "Epoch 40/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1713 - loss: 3.5030\n",
      "Epoch 41/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1848 - loss: 3.4164\n",
      "Epoch 42/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1556 - loss: 3.4655\n",
      "Epoch 43/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2197 - loss: 3.3036\n",
      "Epoch 44/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1801 - loss: 3.2813\n",
      "Epoch 45/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1903 - loss: 3.2626\n",
      "Epoch 46/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1949 - loss: 3.2765\n",
      "Epoch 47/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1824 - loss: 3.2967\n",
      "Epoch 48/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2197 - loss: 3.1715 \n",
      "Epoch 49/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1688 - loss: 3.3607 \n",
      "Epoch 50/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2216 - loss: 3.1838 \n",
      "Epoch 51/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1996 - loss: 3.0727\n",
      "Epoch 52/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2465 - loss: 3.0665\n",
      "Epoch 53/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2612 - loss: 2.9271 \n",
      "Epoch 54/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2294 - loss: 3.0790 \n",
      "Epoch 55/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2549 - loss: 2.9250\n",
      "Epoch 56/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2024 - loss: 2.9535\n",
      "Epoch 57/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2210 - loss: 2.8852\n",
      "Epoch 58/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2520 - loss: 2.7945\n",
      "Epoch 59/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2515 - loss: 2.7884\n",
      "Epoch 60/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2317 - loss: 2.9150 \n",
      "Epoch 61/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2670 - loss: 2.7768\n",
      "Epoch 62/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2859 - loss: 2.6692\n",
      "Epoch 63/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3254 - loss: 2.6363\n",
      "Epoch 64/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3159 - loss: 2.5841\n",
      "Epoch 65/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2974 - loss: 2.6201\n",
      "Epoch 66/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3683 - loss: 2.3775\n",
      "Epoch 67/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3363 - loss: 2.4187\n",
      "Epoch 68/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3546 - loss: 2.3966 \n",
      "Epoch 69/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3670 - loss: 2.3784 \n",
      "Epoch 70/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3879 - loss: 2.2875 \n",
      "Epoch 71/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3601 - loss: 2.3600\n",
      "Epoch 72/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4207 - loss: 2.1311 \n",
      "Epoch 73/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3574 - loss: 2.2862\n",
      "Epoch 74/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3751 - loss: 2.2245\n",
      "Epoch 75/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4052 - loss: 2.2236 \n",
      "Epoch 76/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4064 - loss: 2.1575 \n",
      "Epoch 77/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4209 - loss: 2.0095\n",
      "Epoch 78/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4068 - loss: 1.9849 \n",
      "Epoch 79/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4013 - loss: 1.9681\n",
      "Epoch 80/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3986 - loss: 1.9330\n",
      "Epoch 81/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4477 - loss: 1.8559\n",
      "Epoch 82/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4838 - loss: 1.8122\n",
      "Epoch 83/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4753 - loss: 1.8469\n",
      "Epoch 84/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4463 - loss: 1.7948\n",
      "Epoch 85/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4976 - loss: 1.7233\n",
      "Epoch 86/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5267 - loss: 1.6612\n",
      "Epoch 87/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5603 - loss: 1.5605\n",
      "Epoch 88/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4862 - loss: 1.7714\n",
      "Epoch 89/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4640 - loss: 1.6523\n",
      "Epoch 90/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5029 - loss: 1.5855 \n",
      "Epoch 91/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5658 - loss: 1.5682\n",
      "Epoch 92/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5475 - loss: 1.5369\n",
      "Epoch 93/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5723 - loss: 1.4732 \n",
      "Epoch 94/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5864 - loss: 1.4379 \n",
      "Epoch 95/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5232 - loss: 1.5458\n",
      "Epoch 96/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5897 - loss: 1.4876\n",
      "Epoch 97/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5486 - loss: 1.4578 \n",
      "Epoch 98/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5693 - loss: 1.3916\n",
      "Epoch 99/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5642 - loss: 1.4244 \n",
      "Epoch 100/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6053 - loss: 1.2880\n",
      "Epoch 101/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5830 - loss: 1.4242\n",
      "Epoch 102/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5762 - loss: 1.3608\n",
      "Epoch 103/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6140 - loss: 1.3247\n",
      "Epoch 104/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6296 - loss: 1.2720\n",
      "Epoch 105/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6608 - loss: 1.2444\n",
      "Epoch 106/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6629 - loss: 1.2745\n",
      "Epoch 107/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6608 - loss: 1.2191\n",
      "Epoch 108/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6483 - loss: 1.2229\n",
      "Epoch 109/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6521 - loss: 1.1357 \n",
      "Epoch 110/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6467 - loss: 1.2067\n",
      "Epoch 111/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6816 - loss: 1.1249\n",
      "Epoch 112/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6396 - loss: 1.1694 \n",
      "Epoch 113/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7060 - loss: 1.0750\n",
      "Epoch 114/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6967 - loss: 1.0916\n",
      "Epoch 115/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7202 - loss: 1.0177\n",
      "Epoch 116/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7171 - loss: 1.0285\n",
      "Epoch 117/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7321 - loss: 0.9668\n",
      "Epoch 118/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7116 - loss: 1.0289\n",
      "Epoch 119/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7087 - loss: 0.9991\n",
      "Epoch 120/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7687 - loss: 0.9092\n",
      "Epoch 121/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7514 - loss: 0.9434\n",
      "Epoch 122/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7456 - loss: 0.9409\n",
      "Epoch 123/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7398 - loss: 0.9880\n",
      "Epoch 124/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6838 - loss: 1.0100\n",
      "Epoch 125/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7094 - loss: 1.0012\n",
      "Epoch 126/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7502 - loss: 0.9362\n",
      "Epoch 127/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7521 - loss: 0.8955\n",
      "Epoch 128/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7467 - loss: 0.8444\n",
      "Epoch 129/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7949 - loss: 0.8256\n",
      "Epoch 130/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7992 - loss: 0.8855\n",
      "Epoch 131/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7745 - loss: 0.7803 \n",
      "Epoch 132/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8100 - loss: 0.7833\n",
      "Epoch 133/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8204 - loss: 0.8064\n",
      "Epoch 134/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7928 - loss: 0.8146\n",
      "Epoch 135/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8121 - loss: 0.8160 \n",
      "Epoch 136/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8444 - loss: 0.6982 \n",
      "Epoch 137/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8119 - loss: 0.7799\n",
      "Epoch 138/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8131 - loss: 0.7316 \n",
      "Epoch 139/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8499 - loss: 0.7143 \n",
      "Epoch 140/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7596 - loss: 0.8511\n",
      "Epoch 141/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8460 - loss: 0.6706 \n",
      "Epoch 142/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8137 - loss: 0.7241 \n",
      "Epoch 143/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8297 - loss: 0.7173 \n",
      "Epoch 144/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8432 - loss: 0.6637 \n",
      "Epoch 145/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8132 - loss: 0.6856\n",
      "Epoch 146/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8205 - loss: 0.6813 \n",
      "Epoch 147/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8025 - loss: 0.6467\n",
      "Epoch 148/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8484 - loss: 0.6839 \n",
      "Epoch 149/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8079 - loss: 0.6931\n",
      "Epoch 150/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8363 - loss: 0.6637 \n",
      "Epoch 151/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8337 - loss: 0.6564 \n",
      "Epoch 152/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8579 - loss: 0.6080 \n",
      "Epoch 153/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8206 - loss: 0.7036 \n",
      "Epoch 154/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8745 - loss: 0.5979 \n",
      "Epoch 155/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8233 - loss: 0.7255 \n",
      "Epoch 156/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8261 - loss: 0.6901 \n",
      "Epoch 157/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8749 - loss: 0.5821 \n",
      "Epoch 158/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8458 - loss: 0.5926\n",
      "Epoch 159/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8939 - loss: 0.5473 \n",
      "Epoch 160/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8481 - loss: 0.6051 \n",
      "Epoch 161/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8584 - loss: 0.5481 \n",
      "Epoch 162/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8658 - loss: 0.5559\n",
      "Epoch 163/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8790 - loss: 0.5521 \n",
      "Epoch 164/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8828 - loss: 0.5450 \n",
      "Epoch 165/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8758 - loss: 0.5284 \n",
      "Epoch 166/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8676 - loss: 0.5589\n",
      "Epoch 167/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8668 - loss: 0.4503 \n",
      "Epoch 168/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8610 - loss: 0.5590 \n",
      "Epoch 169/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8505 - loss: 0.5477 \n",
      "Epoch 170/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8553 - loss: 0.5616 \n",
      "Epoch 171/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8654 - loss: 0.5704 \n",
      "Epoch 172/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8930 - loss: 0.4687 \n",
      "Epoch 173/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8609 - loss: 0.5160\n",
      "Epoch 174/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8660 - loss: 0.5484 \n",
      "Epoch 175/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9084 - loss: 0.4338 \n",
      "Epoch 176/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8935 - loss: 0.4619\n",
      "Epoch 177/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8524 - loss: 0.5147 \n",
      "Epoch 178/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8596 - loss: 0.4898\n",
      "Epoch 179/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8825 - loss: 0.5011\n",
      "Epoch 180/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8754 - loss: 0.4713 \n",
      "Epoch 181/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8612 - loss: 0.5434 \n",
      "Epoch 182/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8763 - loss: 0.4836 \n",
      "Epoch 183/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8582 - loss: 0.4895\n",
      "Epoch 184/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8589 - loss: 0.5797 \n",
      "Epoch 185/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8784 - loss: 0.5327\n",
      "Epoch 186/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8873 - loss: 0.4905 \n",
      "Epoch 187/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9248 - loss: 0.3792\n",
      "Epoch 188/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8537 - loss: 0.4845\n",
      "Epoch 189/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8738 - loss: 0.4247\n",
      "Epoch 190/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9218 - loss: 0.4370\n",
      "Epoch 191/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8854 - loss: 0.4526 \n",
      "Epoch 192/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8996 - loss: 0.4071 \n",
      "Epoch 193/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9266 - loss: 0.3593 \n",
      "Epoch 194/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8952 - loss: 0.3815\n",
      "Epoch 195/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9132 - loss: 0.3792 \n",
      "Epoch 196/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9115 - loss: 0.4055 \n",
      "Epoch 197/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8631 - loss: 0.4590\n",
      "Epoch 198/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9049 - loss: 0.4067\n",
      "Epoch 199/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9136 - loss: 0.3907 \n",
      "Epoch 200/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9302 - loss: 0.3528 \n",
      "Epoch 201/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8812 - loss: 0.4194 \n",
      "Epoch 202/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9143 - loss: 0.3537\n",
      "Epoch 203/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8722 - loss: 0.4599 \n",
      "Epoch 204/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8563 - loss: 0.4684 \n",
      "Epoch 205/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9478 - loss: 0.3210\n",
      "Epoch 206/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8848 - loss: 0.4199 \n",
      "Epoch 207/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9155 - loss: 0.4417 \n",
      "Epoch 208/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9214 - loss: 0.3216\n",
      "Epoch 209/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9128 - loss: 0.3514 \n",
      "Epoch 210/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8932 - loss: 0.4244 \n",
      "Epoch 211/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8673 - loss: 0.4430 \n",
      "Epoch 212/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8997 - loss: 0.4059\n",
      "Epoch 213/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8618 - loss: 0.4661 \n",
      "Epoch 214/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9027 - loss: 0.4085 \n",
      "Epoch 215/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9328 - loss: 0.3553 \n",
      "Epoch 216/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.3691 \n",
      "Epoch 217/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9186 - loss: 0.3933 \n",
      "Epoch 218/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8991 - loss: 0.3975 \n",
      "Epoch 219/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9286 - loss: 0.3061\n",
      "Epoch 220/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9171 - loss: 0.3276 \n",
      "Epoch 221/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.2656 \n",
      "Epoch 222/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9427 - loss: 0.3020 \n",
      "Epoch 223/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9400 - loss: 0.2945\n",
      "Epoch 224/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9324 - loss: 0.3690 \n",
      "Epoch 225/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9327 - loss: 0.2877\n",
      "Epoch 226/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9370 - loss: 0.3558\n",
      "Epoch 227/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9205 - loss: 0.3420 \n",
      "Epoch 228/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9186 - loss: 0.3834 \n",
      "Epoch 229/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9358 - loss: 0.2973\n",
      "Epoch 230/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9645 - loss: 0.2211 \n",
      "Epoch 231/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9449 - loss: 0.3350 \n",
      "Epoch 232/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9276 - loss: 0.3231 \n",
      "Epoch 233/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.2378 \n",
      "Epoch 234/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9495 - loss: 0.3008 \n",
      "Epoch 235/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9342 - loss: 0.3109 \n",
      "Epoch 236/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9458 - loss: 0.2635\n",
      "Epoch 237/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9337 - loss: 0.3135 \n",
      "Epoch 238/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9618 - loss: 0.2460\n",
      "Epoch 239/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9296 - loss: 0.3020 \n",
      "Epoch 240/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9265 - loss: 0.3052\n",
      "Epoch 241/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.3413 \n",
      "Epoch 242/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9217 - loss: 0.3005 \n",
      "Epoch 243/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9454 - loss: 0.3159 \n",
      "Epoch 244/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9312 - loss: 0.3399\n",
      "Epoch 245/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9502 - loss: 0.2663 \n",
      "Epoch 246/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9565 - loss: 0.2195 \n",
      "Epoch 247/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9310 - loss: 0.3345\n",
      "Epoch 248/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9236 - loss: 0.3383 \n",
      "Epoch 249/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9359 - loss: 0.3067 \n",
      "Epoch 250/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9454 - loss: 0.3234\n",
      "Epoch 251/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9660 - loss: 0.2383 \n",
      "Epoch 252/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9539 - loss: 0.2390 \n",
      "Epoch 253/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9523 - loss: 0.2549\n",
      "Epoch 254/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9223 - loss: 0.3151 \n",
      "Epoch 255/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9376 - loss: 0.2836\n",
      "Epoch 256/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9664 - loss: 0.2439 \n",
      "Epoch 257/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9604 - loss: 0.2606\n",
      "Epoch 258/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9404 - loss: 0.2819 \n",
      "Epoch 259/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9394 - loss: 0.2452 \n",
      "Epoch 260/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9397 - loss: 0.3011\n",
      "Epoch 261/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9533 - loss: 0.2466 \n",
      "Epoch 262/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9665 - loss: 0.2197 \n",
      "Epoch 263/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9326 - loss: 0.3085 \n",
      "Epoch 264/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9535 - loss: 0.2176\n",
      "Epoch 265/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9468 - loss: 0.2529 \n",
      "Epoch 266/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9272 - loss: 0.2848 \n",
      "Epoch 267/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9381 - loss: 0.2805\n",
      "Epoch 268/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9409 - loss: 0.2595 \n",
      "Epoch 269/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8634 - loss: 0.4431 \n",
      "Epoch 270/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9317 - loss: 0.2870 \n",
      "Epoch 271/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9368 - loss: 0.3606 \n",
      "Epoch 272/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9296 - loss: 0.2825 \n",
      "Epoch 273/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9014 - loss: 0.4123 \n",
      "Epoch 274/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8559 - loss: 0.5032 \n",
      "Epoch 275/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8672 - loss: 0.3771\n",
      "Epoch 276/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9173 - loss: 0.3588 \n",
      "Epoch 277/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8896 - loss: 0.4125 \n",
      "Epoch 278/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8706 - loss: 0.4271\n",
      "Epoch 279/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9461 - loss: 0.3197 \n",
      "Epoch 280/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9497 - loss: 0.3016 \n",
      "Epoch 281/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9313 - loss: 0.3506 \n",
      "Epoch 282/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9716 - loss: 0.2378 \n",
      "Epoch 283/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9606 - loss: 0.2303 \n",
      "Epoch 284/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9634 - loss: 0.2436 \n",
      "Epoch 285/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9399 - loss: 0.2888 \n",
      "Epoch 286/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9549 - loss: 0.2257\n",
      "Epoch 287/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9498 - loss: 0.2486 \n",
      "Epoch 288/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9598 - loss: 0.2022 \n",
      "Epoch 289/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9733 - loss: 0.1596\n",
      "Epoch 290/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9787 - loss: 0.1830 \n",
      "Epoch 291/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9549 - loss: 0.2005 \n",
      "Epoch 292/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9607 - loss: 0.2553 \n",
      "Epoch 293/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9480 - loss: 0.2005\n",
      "Epoch 294/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.2246 \n",
      "Epoch 295/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9348 - loss: 0.2142 \n",
      "Epoch 296/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9631 - loss: 0.1891\n",
      "Epoch 297/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.1964 \n",
      "Epoch 298/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9540 - loss: 0.2049 \n",
      "Epoch 299/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.1505 \n",
      "Epoch 300/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9582 - loss: 0.2326 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c203b77f10>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,020</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">162</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">171</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,020</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │         \u001b[38;5;34m1,020\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │           \u001b[38;5;34m152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m9\u001b[0m)          │           \u001b[38;5;34m162\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m171\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m)            │         \u001b[38;5;34m1,020\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,577</span> (29.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,577\u001b[0m (29.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,525</span> (9.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,525\u001b[0m (9.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,052</span> (19.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,052\u001b[0m (19.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "In short, the University of Technical Education is an ideal learning and research environment\n",
      "['learning', 'and', 'research', 'environment']\n"
     ]
    }
   ],
   "source": [
    "next_words = 4\n",
    "seed_text=\"In short, the University of Technical Education is an ideal\"\n",
    "y_predict=[]\n",
    "def Recommend(seed_text):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list)\n",
    "        predicted_word = tokenizer.index_word[np.argmax(predicted_probs)]\n",
    "        seed_text += \" \" + predicted_word\n",
    "        y_predict.append(predicted_word)\n",
    "    return seed_text\n",
    "y_result=Recommend(seed_text)\n",
    "print(y_result)\n",
    "print(y_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Evaluating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_true = ['learning', 'and', 'research', 'environment']\n",
    "accuracy = accuracy_score(y_true, y_predict)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "precision = precision_score(y_true, y_predict, average='weighted')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y_true, y_predict, average='weighted')\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "f1score = f1_score(y_true, y_predict, average='weighted')\n",
    "print(f\"F1-score: {f1score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning-lTTH8rYd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
