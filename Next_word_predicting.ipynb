{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from sklearn.metrics  import accuracy_score,f1_score,precision_score,recall_score\n",
    "from keras.activations import relu\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np \n",
    "import regex as re \n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Proprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Read the file and divide it into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_sentence_list(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    sentences = [sentence.strip() for sentence in re.split(r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
    "    return sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Create a dictionary for each word in the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ho Chi Minh City University of Technology and Education, with a long and prestigious history in the field of education and research, is a modern school with a rich and diverse learning and research environment.', 'Located in the city center, Ho Chi Minh City University of Technology and Education is not only a provider of professional knowledge but also a vibrant and creative academic community.', 'With modern facilities, classrooms, laboratories and libraries are fully equipped, creating favorable conditions for students and lecturers in the learning and research process.', 'The school is also proud of its team of experienced, highly qualified lecturers who are committed to providing students with the best support and development.', 'Training programs are diverse, flexible and reflect the actual needs of the labor market, giving students the opportunity to develop themselves and prepare for their future careers.', 'In addition, the school also promotes international research and cooperation, creating conditions for students to participate in research projects and exchange with students and lecturers from universities around the world.', '.', 'In short, the University of Technical Education is an ideal learning and research environment, where creativity and discovery are awakened and developed.']\n",
      "{'and': 1, 'the': 2, 'of': 3, 'in': 4, 'research': 5, 'with': 6, 'a': 7, 'students': 8, 'education': 9, 'is': 10, 'are': 11, 'city': 12, 'university': 13, 'school': 14, 'learning': 15, 'also': 16, 'for': 17, 'lecturers': 18, 'to': 19, 'ho': 20, 'chi': 21, 'minh': 22, 'technology': 23, 'modern': 24, 'diverse': 25, 'environment': 26, 'creating': 27, 'conditions': 28, 'long': 29, 'prestigious': 30, 'history': 31, 'field': 32, 'rich': 33, 'located': 34, 'center': 35, 'not': 36, 'only': 37, 'provider': 38, 'professional': 39, 'knowledge': 40, 'but': 41, 'vibrant': 42, 'creative': 43, 'academic': 44, 'community': 45, 'facilities': 46, 'classrooms': 47, 'laboratories': 48, 'libraries': 49, 'fully': 50, 'equipped': 51, 'favorable': 52, 'process': 53, 'proud': 54, 'its': 55, 'team': 56, 'experienced': 57, 'highly': 58, 'qualified': 59, 'who': 60, 'committed': 61, 'providing': 62, 'best': 63, 'support': 64, 'development': 65, 'training': 66, 'programs': 67, 'flexible': 68, 'reflect': 69, 'actual': 70, 'needs': 71, 'labor': 72, 'market': 73, 'giving': 74, 'opportunity': 75, 'develop': 76, 'themselves': 77, 'prepare': 78, 'their': 79, 'future': 80, 'careers': 81, 'addition': 82, 'promotes': 83, 'international': 84, 'cooperation': 85, 'participate': 86, 'projects': 87, 'exchange': 88, 'from': 89, 'universities': 90, 'around': 91, 'world': 92, 'short': 93, 'technical': 94, 'an': 95, 'ideal': 96, 'where': 97, 'creativity': 98, 'discovery': 99, 'awakened': 100, 'developed': 101}\n"
     ]
    }
   ],
   "source": [
    "file_path = 'train.txt'\n",
    "text_data = file_to_sentence_list(file_path)\n",
    "print(text_data)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data) \n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Create Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 21], [20, 21, 22], [20, 21, 22, 12], [20, 21, 22, 12, 13], [20, 21, 22, 12, 13, 3], [20, 21, 22, 12, 13, 3, 23], [20, 21, 22, 12, 13, 3, 23, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15, 1, 5], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15, 1, 5, 26], [34, 4], [34, 4, 2], [34, 4, 2, 12], [34, 4, 2, 12, 35], [34, 4, 2, 12, 35, 20], [34, 4, 2, 12, 35, 20, 21], [34, 4, 2, 12, 35, 20, 21, 22], [34, 4, 2, 12, 35, 20, 21, 22, 12], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1, 43], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1, 43, 44], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1, 43, 44, 45], [6, 24], [6, 24, 46], [6, 24, 46, 47], [6, 24, 46, 47, 48], [6, 24, 46, 47, 48, 1], [6, 24, 46, 47, 48, 1, 49], [6, 24, 46, 47, 48, 1, 49, 11], [6, 24, 46, 47, 48, 1, 49, 11, 50], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15, 1], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15, 1, 5], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15, 1, 5, 53], [2, 14], [2, 14, 10], [2, 14, 10, 16], [2, 14, 10, 16, 54], [2, 14, 10, 16, 54, 3], [2, 14, 10, 16, 54, 3, 55], [2, 14, 10, 16, 54, 3, 55, 56], [2, 14, 10, 16, 54, 3, 55, 56, 3], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63, 64], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63, 64, 1], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63, 64, 1, 65], [66, 67], [66, 67, 11], [66, 67, 11, 25], [66, 67, 11, 25, 68], [66, 67, 11, 25, 68, 1], [66, 67, 11, 25, 68, 1, 69], [66, 67, 11, 25, 68, 1, 69, 2], [66, 67, 11, 25, 68, 1, 69, 2, 70], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17, 79], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17, 79, 80], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17, 79, 80, 81], [4, 82], [4, 82, 2], [4, 82, 2, 14], [4, 82, 2, 14, 16], [4, 82, 2, 14, 16, 83], [4, 82, 2, 14, 16, 83, 84], [4, 82, 2, 14, 16, 83, 84, 5], [4, 82, 2, 14, 16, 83, 84, 5, 1], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90, 91], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90, 91, 2], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90, 91, 2, 92], [4, 93], [4, 93, 2], [4, 93, 2, 13], [4, 93, 2, 13, 3], [4, 93, 2, 13, 3, 94], [4, 93, 2, 13, 3, 94, 9], [4, 93, 2, 13, 3, 94, 9, 10], [4, 93, 2, 13, 3, 94, 9, 10, 95], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11, 100], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11, 100, 1], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11, 100, 1, 101]]\n"
     ]
    }
   ],
   "source": [
    "def CreateInput(text_data):\n",
    "    input_sequences = []\n",
    "    for line in text_data:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences\n",
    "input_sequences=CreateInput(text_data)\n",
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.Convert to full vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Divide the data set into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y =to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Configuration RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, name='embedding_layer')) \n",
    "model.add(SimpleRNN(8, return_sequences=True, activation=relu, name='rnn_layer_1'))\n",
    "model.add(SimpleRNN(9, return_sequences=True, activation=relu, name='rnn_layer_2'))\n",
    "model.add(SimpleRNN(9, activation=relu, name='rnn_layer_3'))\n",
    "model.add(Dense(total_words, activation='softmax', name='output_layer'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Trainning RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "6/6 [==============================] - 14s 19ms/step - loss: 4.6256 - accuracy: 0.0054\n",
      "Epoch 2/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.6212 - accuracy: 0.0486\n",
      "Epoch 3/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.6177 - accuracy: 0.0757\n",
      "Epoch 4/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.6141 - accuracy: 0.0703\n",
      "Epoch 5/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.6095 - accuracy: 0.0649\n",
      "Epoch 6/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.6029 - accuracy: 0.0432\n",
      "Epoch 7/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.5940 - accuracy: 0.0432\n",
      "Epoch 8/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.5787 - accuracy: 0.0541\n",
      "Epoch 9/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.5595 - accuracy: 0.0541\n",
      "Epoch 10/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.5342 - accuracy: 0.0541\n",
      "Epoch 11/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.5108 - accuracy: 0.0649\n",
      "Epoch 12/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.4874 - accuracy: 0.0703\n",
      "Epoch 13/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.4647 - accuracy: 0.0703\n",
      "Epoch 14/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.4386 - accuracy: 0.0595\n",
      "Epoch 15/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.4168 - accuracy: 0.0595\n",
      "Epoch 16/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.3909 - accuracy: 0.0649\n",
      "Epoch 17/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.3658 - accuracy: 0.0703\n",
      "Epoch 18/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3426 - accuracy: 0.0703\n",
      "Epoch 19/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3184 - accuracy: 0.0649\n",
      "Epoch 20/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.2885 - accuracy: 0.0649\n",
      "Epoch 21/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.2651 - accuracy: 0.0757\n",
      "Epoch 22/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.2305 - accuracy: 0.0757\n",
      "Epoch 23/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.2038 - accuracy: 0.0811\n",
      "Epoch 24/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.1785 - accuracy: 0.1081\n",
      "Epoch 25/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.1486 - accuracy: 0.1135\n",
      "Epoch 26/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.1312 - accuracy: 0.1027\n",
      "Epoch 27/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.1057 - accuracy: 0.1081\n",
      "Epoch 28/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.0673 - accuracy: 0.1027\n",
      "Epoch 29/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.0436 - accuracy: 0.1027\n",
      "Epoch 30/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.0105 - accuracy: 0.1081\n",
      "Epoch 31/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.9761 - accuracy: 0.1135\n",
      "Epoch 32/300\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.9546 - accuracy: 0.1189\n",
      "Epoch 33/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.9077 - accuracy: 0.1135\n",
      "Epoch 34/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.8771 - accuracy: 0.1189\n",
      "Epoch 35/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.8420 - accuracy: 0.1297\n",
      "Epoch 36/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.8159 - accuracy: 0.1297\n",
      "Epoch 37/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.7929 - accuracy: 0.1297\n",
      "Epoch 38/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.7620 - accuracy: 0.1351\n",
      "Epoch 39/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.7197 - accuracy: 0.1243\n",
      "Epoch 40/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.6870 - accuracy: 0.1297\n",
      "Epoch 41/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.6547 - accuracy: 0.1243\n",
      "Epoch 42/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.6244 - accuracy: 0.1351\n",
      "Epoch 43/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.5835 - accuracy: 0.1351\n",
      "Epoch 44/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.5512 - accuracy: 0.1405\n",
      "Epoch 45/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.5181 - accuracy: 0.1405\n",
      "Epoch 46/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.4836 - accuracy: 0.1405\n",
      "Epoch 47/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.4649 - accuracy: 0.1405\n",
      "Epoch 48/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.4244 - accuracy: 0.1297\n",
      "Epoch 49/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.3859 - accuracy: 0.1351\n",
      "Epoch 50/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.3468 - accuracy: 0.1405\n",
      "Epoch 51/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.3152 - accuracy: 0.1405\n",
      "Epoch 52/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.2772 - accuracy: 0.1405\n",
      "Epoch 53/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.2343 - accuracy: 0.1568\n",
      "Epoch 54/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1990 - accuracy: 0.1622\n",
      "Epoch 55/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1622 - accuracy: 0.1622\n",
      "Epoch 56/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.1075 - accuracy: 0.1622\n",
      "Epoch 57/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.0610 - accuracy: 0.1676\n",
      "Epoch 58/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.0359 - accuracy: 0.1946\n",
      "Epoch 59/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.9857 - accuracy: 0.2108\n",
      "Epoch 60/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.9433 - accuracy: 0.2054\n",
      "Epoch 61/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.8996 - accuracy: 0.2216\n",
      "Epoch 62/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.8718 - accuracy: 0.2108\n",
      "Epoch 63/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.8264 - accuracy: 0.2270\n",
      "Epoch 64/300\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.7865 - accuracy: 0.2324\n",
      "Epoch 65/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.7440 - accuracy: 0.2270\n",
      "Epoch 66/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.7174 - accuracy: 0.2432\n",
      "Epoch 67/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.6674 - accuracy: 0.2703\n",
      "Epoch 68/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.6198 - accuracy: 0.2865\n",
      "Epoch 69/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.5799 - accuracy: 0.2865\n",
      "Epoch 70/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.5633 - accuracy: 0.2757\n",
      "Epoch 71/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.5190 - accuracy: 0.3081\n",
      "Epoch 72/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.4770 - accuracy: 0.3297\n",
      "Epoch 73/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.4584 - accuracy: 0.3135\n",
      "Epoch 74/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.4220 - accuracy: 0.3459\n",
      "Epoch 75/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.3952 - accuracy: 0.3297\n",
      "Epoch 76/300\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.3677 - accuracy: 0.3189\n",
      "Epoch 77/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.3108 - accuracy: 0.3676\n",
      "Epoch 78/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.2756 - accuracy: 0.3730\n",
      "Epoch 79/300\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.2519 - accuracy: 0.3730\n",
      "Epoch 80/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.2065 - accuracy: 0.3892\n",
      "Epoch 81/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.1871 - accuracy: 0.3892\n",
      "Epoch 82/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.1669 - accuracy: 0.4216\n",
      "Epoch 83/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.1242 - accuracy: 0.4162\n",
      "Epoch 84/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.1222 - accuracy: 0.4162\n",
      "Epoch 85/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.1010 - accuracy: 0.3892\n",
      "Epoch 86/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.0601 - accuracy: 0.4216\n",
      "Epoch 87/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.0234 - accuracy: 0.4216\n",
      "Epoch 88/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.0373 - accuracy: 0.4270\n",
      "Epoch 89/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.9998 - accuracy: 0.4486\n",
      "Epoch 90/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.9698 - accuracy: 0.4324\n",
      "Epoch 91/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.9382 - accuracy: 0.4703\n",
      "Epoch 92/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.8979 - accuracy: 0.4649\n",
      "Epoch 93/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.8607 - accuracy: 0.4973\n",
      "Epoch 94/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.8315 - accuracy: 0.5189\n",
      "Epoch 95/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.8130 - accuracy: 0.5135\n",
      "Epoch 96/300\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.7915 - accuracy: 0.5081\n",
      "Epoch 97/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.8060 - accuracy: 0.5027\n",
      "Epoch 98/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.7515 - accuracy: 0.5405\n",
      "Epoch 99/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.7168 - accuracy: 0.5351\n",
      "Epoch 100/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.7134 - accuracy: 0.5351\n",
      "Epoch 101/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.6766 - accuracy: 0.5676\n",
      "Epoch 102/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.6747 - accuracy: 0.5568\n",
      "Epoch 103/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.6585 - accuracy: 0.5514\n",
      "Epoch 104/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.6383 - accuracy: 0.5514\n",
      "Epoch 105/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.6165 - accuracy: 0.5676\n",
      "Epoch 106/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5960 - accuracy: 0.5892\n",
      "Epoch 107/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.5705 - accuracy: 0.5838\n",
      "Epoch 108/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.5758 - accuracy: 0.6216\n",
      "Epoch 109/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.5412 - accuracy: 0.5892\n",
      "Epoch 110/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5178 - accuracy: 0.5892\n",
      "Epoch 111/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5133 - accuracy: 0.5730\n",
      "Epoch 112/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.5008 - accuracy: 0.5946\n",
      "Epoch 113/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.4886 - accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.4625 - accuracy: 0.5946\n",
      "Epoch 115/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.4396 - accuracy: 0.6216\n",
      "Epoch 116/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.4142 - accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.4012 - accuracy: 0.6270\n",
      "Epoch 118/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.3809 - accuracy: 0.6324\n",
      "Epoch 119/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.3497 - accuracy: 0.6541\n",
      "Epoch 120/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.3316 - accuracy: 0.6595\n",
      "Epoch 121/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.3206 - accuracy: 0.6649\n",
      "Epoch 122/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.3129 - accuracy: 0.6541\n",
      "Epoch 123/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.3080 - accuracy: 0.6486\n",
      "Epoch 124/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.2943 - accuracy: 0.6541\n",
      "Epoch 125/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.2601 - accuracy: 0.6649\n",
      "Epoch 126/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.2446 - accuracy: 0.6811\n",
      "Epoch 127/300\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.2184 - accuracy: 0.6973\n",
      "Epoch 128/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.2115 - accuracy: 0.6811\n",
      "Epoch 129/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1962 - accuracy: 0.7027\n",
      "Epoch 130/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1830 - accuracy: 0.6973\n",
      "Epoch 131/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.1723 - accuracy: 0.7027\n",
      "Epoch 132/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.1602 - accuracy: 0.6919\n",
      "Epoch 133/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.1674 - accuracy: 0.7189\n",
      "Epoch 134/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.1628 - accuracy: 0.6973\n",
      "Epoch 135/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.1533 - accuracy: 0.7027\n",
      "Epoch 136/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1243 - accuracy: 0.6973\n",
      "Epoch 137/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.1127 - accuracy: 0.7027\n",
      "Epoch 138/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.0942 - accuracy: 0.6973\n",
      "Epoch 139/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.0926 - accuracy: 0.6865\n",
      "Epoch 140/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.0813 - accuracy: 0.7189\n",
      "Epoch 141/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.0719 - accuracy: 0.7135\n",
      "Epoch 142/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.0850 - accuracy: 0.6973\n",
      "Epoch 143/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.1480 - accuracy: 0.6865\n",
      "Epoch 144/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.3509 - accuracy: 0.6595\n",
      "Epoch 145/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.6917 - accuracy: 0.5297\n",
      "Epoch 146/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.5991 - accuracy: 0.5297\n",
      "Epoch 147/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.5190 - accuracy: 0.5838\n",
      "Epoch 148/300\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.3667 - accuracy: 0.6432\n",
      "Epoch 149/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.3447 - accuracy: 0.6054\n",
      "Epoch 150/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.3579 - accuracy: 0.6054\n",
      "Epoch 151/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.2447 - accuracy: 0.6432\n",
      "Epoch 152/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.2607 - accuracy: 0.6216\n",
      "Epoch 153/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.2244 - accuracy: 0.6432\n",
      "Epoch 154/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.1246 - accuracy: 0.6919\n",
      "Epoch 155/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.0841 - accuracy: 0.7135\n",
      "Epoch 156/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0468 - accuracy: 0.7135\n",
      "Epoch 157/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.0203 - accuracy: 0.7189\n",
      "Epoch 158/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.0064 - accuracy: 0.7351\n",
      "Epoch 159/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9914 - accuracy: 0.7351\n",
      "Epoch 160/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.9780 - accuracy: 0.7405\n",
      "Epoch 161/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9715 - accuracy: 0.7351\n",
      "Epoch 162/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.9539 - accuracy: 0.7459\n",
      "Epoch 163/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9483 - accuracy: 0.7568\n",
      "Epoch 164/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9331 - accuracy: 0.7568\n",
      "Epoch 165/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9263 - accuracy: 0.7514\n",
      "Epoch 166/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9210 - accuracy: 0.7622\n",
      "Epoch 167/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9138 - accuracy: 0.7568\n",
      "Epoch 168/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9036 - accuracy: 0.7622\n",
      "Epoch 169/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8987 - accuracy: 0.7622\n",
      "Epoch 170/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8899 - accuracy: 0.7730\n",
      "Epoch 171/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8798 - accuracy: 0.7730\n",
      "Epoch 172/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8753 - accuracy: 0.7892\n",
      "Epoch 173/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8650 - accuracy: 0.7838\n",
      "Epoch 174/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8615 - accuracy: 0.7838\n",
      "Epoch 175/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8542 - accuracy: 0.7730\n",
      "Epoch 176/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8480 - accuracy: 0.7946\n",
      "Epoch 177/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8392 - accuracy: 0.7784\n",
      "Epoch 178/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8385 - accuracy: 0.7946\n",
      "Epoch 179/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8323 - accuracy: 0.7892\n",
      "Epoch 180/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8218 - accuracy: 0.8000\n",
      "Epoch 181/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8174 - accuracy: 0.7946\n",
      "Epoch 182/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8145 - accuracy: 0.8054\n",
      "Epoch 183/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.8050 - accuracy: 0.7892\n",
      "Epoch 184/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7973 - accuracy: 0.7946\n",
      "Epoch 185/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7971 - accuracy: 0.7892\n",
      "Epoch 186/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8002 - accuracy: 0.8000\n",
      "Epoch 187/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7853 - accuracy: 0.8054\n",
      "Epoch 188/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7854 - accuracy: 0.8000\n",
      "Epoch 189/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7759 - accuracy: 0.7946\n",
      "Epoch 190/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7772 - accuracy: 0.8054\n",
      "Epoch 191/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7687 - accuracy: 0.8162\n",
      "Epoch 192/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7612 - accuracy: 0.8054\n",
      "Epoch 193/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7564 - accuracy: 0.8162\n",
      "Epoch 194/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7680 - accuracy: 0.7892\n",
      "Epoch 195/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7740 - accuracy: 0.7946\n",
      "Epoch 196/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8638 - accuracy: 0.7838\n",
      "Epoch 197/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8144 - accuracy: 0.7622\n",
      "Epoch 198/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9142 - accuracy: 0.7243\n",
      "Epoch 199/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8773 - accuracy: 0.7405\n",
      "Epoch 200/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8520 - accuracy: 0.7405\n",
      "Epoch 201/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8269 - accuracy: 0.7892\n",
      "Epoch 202/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8820 - accuracy: 0.7405\n",
      "Epoch 203/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8415 - accuracy: 0.7730\n",
      "Epoch 204/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8613 - accuracy: 0.7568\n",
      "Epoch 205/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8545 - accuracy: 0.7405\n",
      "Epoch 206/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8456 - accuracy: 0.7568\n",
      "Epoch 207/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8538 - accuracy: 0.7676\n",
      "Epoch 208/300\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.7903 - accuracy: 0.7892\n",
      "Epoch 209/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8578 - accuracy: 0.7459\n",
      "Epoch 210/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7931 - accuracy: 0.7838\n",
      "Epoch 211/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7753 - accuracy: 0.7946\n",
      "Epoch 212/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7749 - accuracy: 0.8000\n",
      "Epoch 213/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7375 - accuracy: 0.8108\n",
      "Epoch 214/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7255 - accuracy: 0.8162\n",
      "Epoch 215/300\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.7067 - accuracy: 0.8216\n",
      "Epoch 216/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7009 - accuracy: 0.8162\n",
      "Epoch 217/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6873 - accuracy: 0.8162\n",
      "Epoch 218/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6905 - accuracy: 0.8108\n",
      "Epoch 219/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6790 - accuracy: 0.8216\n",
      "Epoch 220/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6706 - accuracy: 0.8270\n",
      "Epoch 221/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6622 - accuracy: 0.8378\n",
      "Epoch 222/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6562 - accuracy: 0.8432\n",
      "Epoch 223/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6501 - accuracy: 0.8378\n",
      "Epoch 224/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6470 - accuracy: 0.8324\n",
      "Epoch 225/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6403 - accuracy: 0.8378\n",
      "Epoch 226/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6377 - accuracy: 0.8324\n",
      "Epoch 227/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6320 - accuracy: 0.8324\n",
      "Epoch 228/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6315 - accuracy: 0.8378\n",
      "Epoch 229/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6239 - accuracy: 0.8324\n",
      "Epoch 230/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6226 - accuracy: 0.8270\n",
      "Epoch 231/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6172 - accuracy: 0.8378\n",
      "Epoch 232/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6161 - accuracy: 0.8432\n",
      "Epoch 233/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6154 - accuracy: 0.8378\n",
      "Epoch 234/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6064 - accuracy: 0.8324\n",
      "Epoch 235/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6038 - accuracy: 0.8432\n",
      "Epoch 236/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6119 - accuracy: 0.8432\n",
      "Epoch 237/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6178 - accuracy: 0.8324\n",
      "Epoch 238/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5960 - accuracy: 0.8486\n",
      "Epoch 239/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5961 - accuracy: 0.8432\n",
      "Epoch 240/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5916 - accuracy: 0.8432\n",
      "Epoch 241/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5854 - accuracy: 0.8486\n",
      "Epoch 242/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5826 - accuracy: 0.8432\n",
      "Epoch 243/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5825 - accuracy: 0.8378\n",
      "Epoch 244/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5734 - accuracy: 0.8486\n",
      "Epoch 245/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5690 - accuracy: 0.8486\n",
      "Epoch 246/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5687 - accuracy: 0.8432\n",
      "Epoch 247/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5684 - accuracy: 0.8541\n",
      "Epoch 248/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5663 - accuracy: 0.8541\n",
      "Epoch 249/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5599 - accuracy: 0.8649\n",
      "Epoch 250/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5616 - accuracy: 0.8595\n",
      "Epoch 251/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5580 - accuracy: 0.8486\n",
      "Epoch 252/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6193 - accuracy: 0.8432\n",
      "Epoch 253/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6774 - accuracy: 0.8108\n",
      "Epoch 254/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.8283 - accuracy: 0.7622\n",
      "Epoch 255/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9503 - accuracy: 0.7135\n",
      "Epoch 256/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9378 - accuracy: 0.7568\n",
      "Epoch 257/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1825 - accuracy: 0.6865\n",
      "Epoch 258/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.0901 - accuracy: 0.6973\n",
      "Epoch 259/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8686 - accuracy: 0.7243\n",
      "Epoch 260/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.7751 - accuracy: 0.7730\n",
      "Epoch 261/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6778 - accuracy: 0.8378\n",
      "Epoch 262/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6917 - accuracy: 0.8270\n",
      "Epoch 263/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8188 - accuracy: 0.7892\n",
      "Epoch 264/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9910 - accuracy: 0.7568\n",
      "Epoch 265/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9452 - accuracy: 0.7243\n",
      "Epoch 266/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1156 - accuracy: 0.7081\n",
      "Epoch 267/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7692 - accuracy: 0.7622\n",
      "Epoch 268/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9393 - accuracy: 0.7676\n",
      "Epoch 269/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8108 - accuracy: 0.7838\n",
      "Epoch 270/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6787 - accuracy: 0.8054\n",
      "Epoch 271/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6494 - accuracy: 0.8216\n",
      "Epoch 272/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6165 - accuracy: 0.8270\n",
      "Epoch 273/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5850 - accuracy: 0.8541\n",
      "Epoch 274/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5771 - accuracy: 0.8595\n",
      "Epoch 275/300\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5721 - accuracy: 0.8541\n",
      "Epoch 276/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5578 - accuracy: 0.8541\n",
      "Epoch 277/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5475 - accuracy: 0.8541\n",
      "Epoch 278/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5446 - accuracy: 0.8595\n",
      "Epoch 279/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.5375 - accuracy: 0.8649\n",
      "Epoch 280/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5251 - accuracy: 0.8703\n",
      "Epoch 281/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5248 - accuracy: 0.8649\n",
      "Epoch 282/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5194 - accuracy: 0.8649\n",
      "Epoch 283/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5162 - accuracy: 0.8595\n",
      "Epoch 284/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5095 - accuracy: 0.8703\n",
      "Epoch 285/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5094 - accuracy: 0.8703\n",
      "Epoch 286/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5044 - accuracy: 0.8649\n",
      "Epoch 287/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5007 - accuracy: 0.8649\n",
      "Epoch 288/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4969 - accuracy: 0.8649\n",
      "Epoch 289/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4948 - accuracy: 0.8703\n",
      "Epoch 290/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4943 - accuracy: 0.8649\n",
      "Epoch 291/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4911 - accuracy: 0.8649\n",
      "Epoch 292/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4865 - accuracy: 0.8703\n",
      "Epoch 293/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4851 - accuracy: 0.8703\n",
      "Epoch 294/300\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.4836 - accuracy: 0.8649\n",
      "Epoch 295/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4798 - accuracy: 0.8811\n",
      "Epoch 296/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4766 - accuracy: 0.8649\n",
      "Epoch 297/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4747 - accuracy: 0.8649\n",
      "Epoch 298/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4703 - accuracy: 0.8703\n",
      "Epoch 299/300\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4657 - accuracy: 0.8757\n",
      "Epoch 300/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.4677 - accuracy: 0.8649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20caf36ced0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_layer (Embedding  (None, None, 10)          1020      \n",
      " )                                                               \n",
      "                                                                 \n",
      " rnn_layer_1 (SimpleRNN)     (None, None, 8)           152       \n",
      "                                                                 \n",
      " rnn_layer_2 (SimpleRNN)     (None, None, 9)           162       \n",
      "                                                                 \n",
      " rnn_layer_3 (SimpleRNN)     (None, 9)                 171       \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 102)               1020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2525 (9.86 KB)\n",
      "Trainable params: 2525 (9.86 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "In short, the University of Technical Education is an ideal learning and research environment\n",
      "['learning', 'and', 'research', 'environment']\n"
     ]
    }
   ],
   "source": [
    "next_words = 4\n",
    "seed_text=\"In short, the University of Technical Education is an ideal\"\n",
    "y_predict=[]\n",
    "def Recommend(seed_text):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list)\n",
    "        predicted_word = tokenizer.index_word[np.argmax(predicted_probs)]\n",
    "        seed_text += \" \" + predicted_word\n",
    "        y_predict.append(predicted_word)\n",
    "    return seed_text\n",
    "y_result=Recommend(seed_text)\n",
    "print(y_result)\n",
    "print(y_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Evaluating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_true = ['learning', 'and', 'research', 'environment']\n",
    "accuracy = accuracy_score(y_true, y_predict)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "precision = precision_score(y_true, y_predict, average='weighted')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y_true, y_predict, average='weighted')\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "f1score = f1_score(y_true, y_predict, average='weighted')\n",
    "print(f\"F1-score: {f1score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning-lTTH8rYd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
